{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“““15 亿参数 GPT2 中文预训练模型 | 1.5B GPT2 Pretrained Chinese Model”的副本”的副本”的副本",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dalingdao/360/blob/master/%E2%80%9C%E2%80%9C%E2%80%9C15_%E4%BA%BF%E5%8F%82%E6%95%B0_GPT2_%E4%B8%AD%E6%96%87%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B_%7C_1_5B_GPT2_Pretrained_Chinese_Model%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC%E2%80%9D%E7%9A%84%E5%89%AF%E6%9C%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3Xx3Nu9IWRN",
        "colab_type": "text"
      },
      "source": [
        "[![GitHub stars](https://img.shields.io/github/stars/imcaspar/gpt2-ml?style=social)](https://github.com/imcaspar/gpt2-ml)\n",
        "[![GitHub](https://img.shields.io/github/license/imcaspar/gpt2-ml)](https://github.com/imcaspar/gpt2-ml)\n",
        "[![Twitter URL](https://img.shields.io/twitter/url?style=social&url=https%3A%2F%2Fgithub.com%2Fimcaspar%2Fgpt2-ml)](https://twitter.com/intent/tweet?text=Wow:&url=https://github.com/imcaspar/gpt2-ml)\n",
        "# Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NmrmoGcIWRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!git clone -q https://github.com/imcaspar/gpt2-ml\n",
        "%cd /content/gpt2-ml\n",
        "!mkdir -p /content/gpt2-ml/models/mega\n",
        "\n",
        "!chmod +x 3rd/gdown.pl/gdown.pl\n",
        "!3rd/gdown.pl/gdown.pl https://drive.google.com/open?id=1n_5-tgPpQ1gqbyLPbP1PwiFi2eo7SWw_ models/mega/model.ckpt-100000.data-00000-of-00001\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.index -P models/mega\n",
        "!wget -q --show-progress https://github.com/imcaspar/gpt2-ml/releases/download/v0.5/model.ckpt-100000.meta -P models/mega"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm3eoxOWIWRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" If gdown.pl failed, please uncomment following code & exec\n",
        "from google.colab import auth\n",
        "from googleapiclient.discovery import build\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "from tqdm import tqdm\n",
        "\n",
        "auth.authenticate_user()\n",
        "drive_service = build('drive', 'v3')\n",
        "\n",
        "file_id, file_ext = ('1n_5-tgPpQ1gqbyLPbP1PwiFi2eo7SWw_', '.data-00000-of-00001')\n",
        "filename = '%s/model.ckpt-%d%s' % (model_dir, 100000, file_ext)\n",
        "req = drive_service.files().get_media(fileId=file_id)\n",
        "with open(filename, 'wb') as f:\n",
        "    downloader = MediaIoBaseDownload(f, req, chunksize=100*1024*1024)\n",
        "    done = False\n",
        "    pbar = tqdm(total=100, desc='%s' % filename)\n",
        "    progress = 0\n",
        "    while done is False:\n",
        "        status, done = downloader.next_chunk()\n",
        "        new_progress = int(status.progress() * 100)\n",
        "        pbar.update(new_progress - progress)\n",
        "        progress = new_progress\n",
        "    pbar.close()\n",
        "\"\"\";"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43eoUad6IWRr",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlPqTIeXJBWv",
        "colab_type": "text"
      },
      "source": [
        "# 新段落"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9XMlfNDIWRu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!PYTHONPATH=$(pwd) python3 scripts/interactive_conditional_samples.py -model_config_fn configs/mega.json -model_ckpt models/mega/model.ckpt-100000 -samples 10"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}